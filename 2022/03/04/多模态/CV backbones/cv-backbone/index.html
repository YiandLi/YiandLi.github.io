<!DOCTYPE html>
<html lang="zh-Hans">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":20,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="如何看待何恺明最新一作论文Masked Autoencoders Vision Transformer , 通用 Vision Backbone 超详细解读 (原理分析+代码解读) (目录) 本文依据CVPR 2023教程All Things ViTs: Understanding and Interpreting Attention in Vision 所整理   CNN 中的 inductiv">
<meta property="og:type" content="article">
<meta property="og:title" content="cv-backbone">
<meta property="og:url" content="http://example.com/2022/03/04/%E5%A4%9A%E6%A8%A1%E6%80%81/CV%20backbones/cv-backbone/index.html">
<meta property="og:site_name" content="Yili">
<meta property="og:description" content="如何看待何恺明最新一作论文Masked Autoencoders Vision Transformer , 通用 Vision Backbone 超详细解读 (原理分析+代码解读) (目录) 本文依据CVPR 2023教程All Things ViTs: Understanding and Interpreting Attention in Vision 所整理   CNN 中的 inductiv">
<meta property="og:locale">
<meta property="og:image" content="https://pic2.zhimg.com/80/v2-a29d52c726d21c0afb910c36defdc045_1440w.webp">
<meta property="og:image" content="https://pic2.zhimg.com/80/v2-b7da716d19c9ccd0f1d2ddc07a68bf79_1440w.jpg">
<meta property="og:image" content="https://pic1.zhimg.com/80/v2-9465797b4cc9e09a0d0c961de53bf594_1440w.jpg?source=1940ef5c">
<meta property="og:image" content="http://example.com/images/%E5%A4%9A%E6%A8%A1%E6%80%81/MAE.png">
<meta property="article:published_time" content="2022-03-05T06:44:21.000Z">
<meta property="article:modified_time" content="2024-07-13T07:27:03.433Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://pic2.zhimg.com/80/v2-a29d52c726d21c0afb910c36defdc045_1440w.webp">

<link rel="canonical" href="http://example.com/2022/03/04/%E5%A4%9A%E6%A8%A1%E6%80%81/CV%20backbones/cv-backbone/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-Hans'
  };
</script>

  <title>cv-backbone | Yili</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --></head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Yili</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">Suggest Google Chrome for better math Reading.</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/2022/03/04/%E5%A4%9A%E6%A8%A1%E6%80%81/CV%20backbones/cv-backbone/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="A foolish, slow learner.">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Yili">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          cv-backbone
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-03-04 22:44:21" itemprop="dateCreated datePublished" datetime="2022-03-04T22:44:21-08:00">2022-03-04</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/MultiModal/" itemprop="url" rel="index"><span itemprop="name">MultiModal</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="Symbols count in article">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">Symbols count in article: </span>
              <span>4.2k</span>
            </span>
            <span class="post-meta-item" title="Reading time">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">Reading time &asymp;</span>
              <span>21 mins.</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/498364155/answer/2240224120">如何看待何恺明最新一作论文Masked Autoencoders</a><br />
<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/348593638">Vision Transformer , 通用 Vision Backbone 超详细解读 (原理分析+代码解读) (目录)</a><br />
<a target="_blank" rel="noopener" href="https://www.zhihu.com/question/485458547/answer/3093372098">本文依据CVPR 2023教程All Things ViTs: Understanding and Interpreting Attention in Vision 所整理 </a></p>
<h1 id="cnn-中的-inductive-biases"><a class="markdownIt-Anchor" href="#cnn-中的-inductive-biases"></a> CNN 中的 inductive biases</h1>
<p>什么是归纳性偏好：一种用于根据情况进行「模型选择」的「先验」。</p>
<p>两个归纳偏执 inductive biases ，是 transformer 不具备的：</p>
<ol>
<li>locality：元素相关性近大远小，相邻的区域相关性更强。</li>
<li>translation equivalence： 卷积核共享权重， <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi>g</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo>=</mo><mi>g</mi><mo stretchy="false">(</mo><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">f(g(x)) =  g(f(x))</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mclose">)</span></span></span></span> 先平移还是先卷积，效果差不多。即同一个物体，不论是平移（移动到不同区域）到哪里，遇到同一个卷积核，输出都是一样的。</li>
</ol>
<p>这两个 biases 让 CNN 比 transformer 学的更快，即在相对少的数据上训练的结果更好。<br />
换言之， vit 需要更多的数据进行预训练，才能学到更好的知识。</p>
<h1 id="resnet"><a class="markdownIt-Anchor" href="#resnet"></a> ResNet</h1>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/35985680">一文简述ResNet及其多种变体</a></p>
<p>「恒等快捷连接」（identity shortcut connection）</p>
<p>后续论文提出预激活机制，类似 pre-norm，即先 BN + ReLu，在进行卷积变换。</p>
<h2 id="resnext"><a class="markdownIt-Anchor" href="#resnext"></a> ResNext</h2>
<p>提出一种多通道结构，和 [4] 中的 Inception 模块非常相似，遵循「分割-转换-合并」范式。但是这里是平行的，同时遵循相同的拓扑结构。</p>
<p>同时提出超参数 <strong>Cardinality 「基数」</strong> ：指独立路径的数量，它只有一个简单的范式和一个需要调整的超参数，而 Inception 需要调整很多超参数（比如每个路径的卷积层内核大小）。</p>
<p>提出的左边的结构等价于 b，c 结构：<br />
<img src="https://pic2.zhimg.com/80/v2-a29d52c726d21c0afb910c36defdc045_1440w.webp" alt="" /></p>
<h1 id="igpt"><a class="markdownIt-Anchor" href="#igpt"></a> iGPT</h1>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/352350329">iGPT详解</a><br />
使用 bert 和 gpt 结构训练 cv ，把图像马赛克掉，变成一个个色块，数量一下就减少了 。</p>
<p>和后面的区别就是 ，这里使用了马赛克化这种降采样方式，为每个像素点预训练一个 token，问题是从输入上就降低了模型的拟合能力。</p>
<p>数据预处理：</p>
<ol>
<li>降采样，即调低分辨率，分别是 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3</mn><msup><mn>2</mn><mn>2</mn></msup><mo>×</mo><mn>3</mn><mo separator="true">,</mo><mn>4</mn><msup><mn>8</mn><mn>2</mn></msup><mo>×</mo><mn>3</mn><mo separator="true">,</mo><mn>6</mn><msup><mn>4</mn><mn>2</mn></msup><mo>×</mo><mn>3</mn></mrow><annotation encoding="application/x-tex">32^2\times 3, 48^2\times 3, 64^2\times 3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.897438em;vertical-align:-0.08333em;"></span><span class="mord">3</span><span class="mord"><span class="mord">2</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.008548em;vertical-align:-0.19444em;"></span><span class="mord">3</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">4</span><span class="mord"><span class="mord">8</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.008548em;vertical-align:-0.19444em;"></span><span class="mord">3</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">6</span><span class="mord"><span class="mord">4</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">3</span></span></span></span> ，叫做输入分辨率（Input Resolution，IR）。</li>
<li>为了进一步缓解计算压力，作者对标准的(R, G, B)图像数据进行了 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi><mo>=</mo><mn>512</mn></mrow><annotation encoding="application/x-tex">k=512</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">5</span><span class="mord">1</span><span class="mord">2</span></span></span></span> 的 k-means 聚类，将通道数量降低为 1，即得到 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3</mn><msup><mn>2</mn><mn>2</mn></msup><mo separator="true">,</mo><mn>4</mn><msup><mn>8</mn><mn>2</mn></msup><mo separator="true">,</mo><mn>6</mn><msup><mn>4</mn><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">32^2, 48^2, 64^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.008548em;vertical-align:-0.19444em;"></span><span class="mord">3</span><span class="mord"><span class="mord">2</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">4</span><span class="mord"><span class="mord">8</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">6</span><span class="mord"><span class="mord">4</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span> 的图片，作者将这个分辨率叫做模型分辨率（Model Resolution，MR）。<br />
这里应该是将通道长度为3的向量作为一个点，进行聚类，最终词表为 512。</li>
</ol>
<p>后面就是 bert 或者 gpt 的预训练结构，输入就是将上面的 Model Resolution，MR 顺序 flatten 成为 1d 结构</p>
<h1 id="ipt"><a class="markdownIt-Anchor" href="#ipt"></a> IPT</h1>
<h1 id="vit"><a class="markdownIt-Anchor" href="#vit"></a> VIT</h1>
<p><strong>bert 架构</strong>，没有使用 mlm task，而是使用 cls 分类任务。<br />
输入为原始的 flattened patch embedding。</p>
<p>2d 图像转序列化: 将原始的图片切分成为 patch 块列表</p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>H</mi><mo>×</mo><mi>W</mi><mo>×</mo><mi>C</mi><mo>⟶</mo><mi>P</mi><mo>×</mo><mi>P</mi><mo>×</mo><mi>C</mi></mrow><annotation encoding="application/x-tex">H\times W \times C \longrightarrow P\times P \times C</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.69433em;vertical-align:-0.011em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">⟶</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span></span></span></span> ，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi></mrow><annotation encoding="application/x-tex">P</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span></span></span></span> 表示 patch size，Height（高度）、Width（宽度）和Channels（通道数）。<br />
于是就可以将原本的图片切分成为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span></span></span></span> 个 patch，然后将每一个 path 进行 flatten，得到一个一维向量，然后加上 1d 位置编码，作者也尝试 相对位置编码 / 2d（原本一个位置编码长度为 d，这里里用两个 d/2 的向量分别表示横纵坐标，然后拼接，那么同一列的向量的后面的 d/2 的向量就一样了），但是效果差不多。作者认为是因为 patch 数量不多，对位置不敏感。</p>
<p>于是得到了 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi><mo>×</mo><mrow><mo fence="true">(</mo><msup><mi>P</mi><mn>2</mn></msup><mi>C</mi><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">N \times\left(P^2 C\right)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.20001em;vertical-align:-0.35001em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size1">(</span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size1">)</span></span></span></span></span></span> 的序列，可以看成是 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>Sequence Length</mtext><mo>∗</mo><mtext>Hidden State</mtext></mrow><annotation encoding="application/x-tex">\text{Sequence Length} * \text{Hidden State}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord text"><span class="mord">Sequence Length</span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord text"><span class="mord">Hidden State</span></span></span></span></span> ，即 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>P</mi><mn>2</mn></msup><mi>C</mi></mrow><annotation encoding="application/x-tex">P^2 C</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span></span></span></span> 为词向量大小。</p>
<p>因为输入图片的长宽都不一致，导致固定的 patch size 下，出现不同数量的 patch 数量。</p>
<ul>
<li>
<p>如果修改 patch size，虽然可以得到相同数量的 patch，但是输入维度就不一样了。<br />
为了避免模型结构受到 patch size 的影响，作者 <span style="color:red;"> <strong>对上述过程得到的 flattened patches 向量做了 Linear Projection</strong> </span>（如下图所示），将不同长度的 flattened patch 向量转化为固定长度的向量 。</p>
</li>
<li>
<p>而对于高分辨率图像，如果保持 patch 大小不变，得到的 patch 个数将增加，超过了预训练的最大个数，所以为了拓展位置编码，这里使用了2D插值的方法：<a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_44166630/article/details/127429697">ViT 微调时关于position embedding如何插值（interpolate）的详解</a> 。</p>
</li>
</ul>
<p>然后加上单独的 [cls] token 和可以学习的位置编码，得到最终的输入。</p>
<p><img src="https://pic2.zhimg.com/80/v2-b7da716d19c9ccd0f1d2ddc07a68bf79_1440w.jpg" alt="" /></p>
<p>训练方法：跟传统CV一样，进行有监督的预训练。 [cls] 作为整体特征分类，没有使用 MLM。</p>
<p>在传统 resnet 中，最后一层编码为 14*14，然后 globally average pooling（GAP） 得到一个 14维度 向量 ，然后分类的。</p>
<p>结论：在中等规模的数据集上（例如ImageNet），transformer模型的表现不如ResNets；而当数据集的规模扩大，transformer模型的效果接近或者超过 SOTA。</p>
<p>作者认为是大规模的训练可以鼓励transformer学到CNN结构所拥有的 translation equivariance (<a target="_blank" rel="noopener" href="https://aboveintelligent.com/ml-cnn-translation-equivariance-and-invariance-da12e8ab7049">解释看这里</a>) 和locality.</p>
<h2 id="归纳偏执分析"><a class="markdownIt-Anchor" href="#归纳偏执分析"></a> 归纳偏执分析</h2>
<p>transformer 没有 inductive bias 局部性，平移不变形 ，但是在 CNN 中这两个先验知识贯穿模型始终；同时也没有使用图片的 2d 信息。</p>
<p>关于inductive bias ，即同一个网路对应全局的token，即一个卷积核对应了多个 patch，而这里只有 mlp 满足，而 attention 是 global 的，不是 local 的（有点 不能理解）。</p>
<p>位置编码也是需要重新学.整个 model 没有2d 信息。</p>
<h2 id="混合结构"><a class="markdownIt-Anchor" href="#混合结构"></a> 混合结构</h2>
<p>先用卷积 cnn ，得到特征图  <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>14</mn><mo>∗</mo><mn>14</mn><mo>∗</mo><mn>768</mn></mrow><annotation encoding="application/x-tex">14*14*768</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span><span class="mord">4</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span><span class="mord">4</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">7</span><span class="mord">6</span><span class="mord">8</span></span></span></span> ，其实就是两种初始化方法，后续操作都是一样。</p>
<h1 id="beit"><a class="markdownIt-Anchor" href="#beit"></a> BEiT</h1>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/381345343">Self-Supervised Learning 超详细解读 (三)：BEiT：视觉BERT预训练模型</a><br />
<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/562957629">图像预训练：BEIT</a></p>
<p>上面的方法还是倾向于有监督的，没有办法给到一个符合原本图片的预训练目标，也就没有办法充分利用 MLM 。</p>
<p><strong>bert 架构</strong>，使用了 mlm task，但是还原的目标不是原始的 patch embedding，而是 encoded embedding。</p>
<p>定义了两种图片的表示模型：</p>
<ul>
<li><strong>image patches</strong>: 和 VIT 一致，原始的 flattened mapped patch embedding，即 展平成向量并通过线性变换操作 (flattened into vectors and are linearly projected)， 用于保留图片的原始信息 (Preserve raw pixels)，作为输入。</li>
<li><strong>visual tokens</strong>：用作输出的监督信号</li>
</ul>
<p>结构： BERT结构 + dVAE</p>
<br>
<p><strong>dVAE discrete variational autoencoder (dVAE)</strong>，参考 DALL-E<br />
即在编码时，将原始输入，也就是 224×224 的输入图片，编码为一个 14×14 个 visual token ，这里也讲过这个编码器称为 tokenizer 。每个 visual token 是一个位于 [1,8192] 之间的数字，即词典 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>V</mi></mrow><annotation encoding="application/x-tex">V</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span></span></span></span> 大小为 8192，每个 16×16 的image patch会经过 Tokenizer 映射成 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">∣</mi><mi>V</mi><mi mathvariant="normal">∣</mi></mrow><annotation encoding="application/x-tex">|V|</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">∣</span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mord">∣</span></span></span></span> 里面的一个词。<br />
因为 visual token 是离散的数，所以优化时没法求导，所以作者采用了 gumbel softmax 技巧</p>
<p>作者这里先用这种方法训练一个 dVAE，用 encoder 作为 tokenizer，作为 mlm 的监督对象。</p>
<p><img src="https://pic1.zhimg.com/80/v2-9465797b4cc9e09a0d0c961de53bf594_1440w.jpg?source=1940ef5c" alt="" /></p>
<p>输入还是 flattened patch embedding，先将原本图片切成 N 个 patch，即 $N\times P^2C $ ；然后 faltten patch ，再用 mlp 转换维度，将其转换为 d 维度向量，加上位置编码得到输入。<br />
另一种解读方式，使用 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi></mrow><annotation encoding="application/x-tex">d</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">d</span></span></span></span> 个 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo>∗</mo><mi>P</mi><mo>∗</mo><mi>C</mi></mrow><annotation encoding="application/x-tex">P*P*C</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span></span></span></span> 的卷积层，步长为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi></mrow><annotation encoding="application/x-tex">P</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span></span></span></span> 进行变换。<br />
然后就是过mask  40%，然后过 bert，遵循 mlm 方式，最后一层后把盖住的部分通过一个分类器，去预测盖住的token，因为这里是离散的 token id，所以是过一个 classifier，让分类概率最大。属于输入连续的 patch vector，输出目标为 vocab id。</p>
<p>训练时候分两步：</p>
<ol>
<li>只训练 dVAE 的 Tokenizer 和 Decoder</li>
<li>冻结 dVAE，只训练 encoder</li>
</ol>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><munder><mo>∑</mo><mrow><mrow><mo fence="true">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo separator="true">,</mo><msub><mover accent="true"><mi>x</mi><mo>~</mo></mover><mi>i</mi></msub><mo fence="true">)</mo></mrow><mo>∈</mo><mi mathvariant="script">D</mi></mrow></munder><mo stretchy="false">(</mo><munder><munder><mrow><msub><mi>E</mi><mrow><msub><mi>z</mi><mi>i</mi></msub><mo>∼</mo><msub><mi>q</mi><mi>ϕ</mi></msub><mrow><mo fence="true">(</mo><mi>z</mi><mo>∣</mo><msub><mi>x</mi><mi>i</mi></msub><mo fence="true">)</mo></mrow></mrow></msub><mrow><mo fence="true">[</mo><mi>log</mi><mo>⁡</mo><msub><mi>p</mi><mi>ψ</mi></msub><mrow><mo fence="true">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo>∣</mo><msub><mi>z</mi><mi>i</mi></msub><mo fence="true">)</mo></mrow><mo fence="true">]</mo></mrow></mrow><mo stretchy="true">⏟</mo></munder><mtext>Stage 1: Visual Token Reconstruction </mtext></munder><mo>+</mo><munder><munder><mrow><mi>log</mi><mo>⁡</mo><msub><mi>p</mi><mi>θ</mi></msub><mrow><mo fence="true">(</mo><msub><mover accent="true"><mi>z</mi><mo>^</mo></mover><mi>i</mi></msub><mo>∣</mo><msub><mover accent="true"><mi>x</mi><mo>~</mo></mover><mi>i</mi></msub><mo fence="true">)</mo></mrow></mrow><mo stretchy="true">⏟</mo></munder><mtext>Stage 2: Masked Image Modeling </mtext></munder><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\sum_{\left(x_i, \tilde{x}_i\right) \in \mathcal{D}}(\underbrace{E_{z_i \sim q_\phi\left(z \mid x_i\right)}\left[\log p_\psi\left(x_i \mid z_i\right)\right]}_{\text {Stage 1: Visual Token Reconstruction }}+\underbrace{\log p_\theta\left(\hat{z}_i \mid \tilde{x}_i\right)}_{\text {Stage 2: Masked Image Modeling }})
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:2.9035009999999994em;vertical-align:-1.8534959999999996em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.050005em;"><span style="top:-1.808995em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="minner mtight"><span class="mopen mtight delimcenter" style="top:0em;"><span class="mtight">(</span></span><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3280857142857143em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mpunct mtight">,</span><span class="mord mtight"><span class="mord accent mtight"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6678599999999999em;"><span style="top:-2.7em;"><span class="pstrut" style="height:2.7em;"></span><span class="mord mtight"><span class="mord mathnormal mtight">x</span></span></span><span style="top:-3.0500000000000003em;"><span class="pstrut" style="height:2.7em;"></span><span class="accent-body" style="left:-0.22222em;"><span class="mord mtight">~</span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3280857142857143em;"><span style="top:-2.357em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mclose mtight delimcenter" style="top:0em;"><span class="mtight">)</span></span></span><span class="mrel mtight">∈</span><span class="mord mtight"><span class="mord mathcal mtight" style="margin-right:0.02778em;">D</span></span></span></span></span><span style="top:-3.0500049999999996em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.516005em;"><span></span></span></span></span></span><span class="mopen">(</span><span class="mord munder"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.75em;"><span style="top:-1.2826120000000003em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">Stage 1: Visual Token Reconstruction </span></span></span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord munder"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7500000000000001em;"><span class="svg-align" style="top:-1.9687200000000002em;"><span class="pstrut" style="height:3em;"></span><span class="stretchy" style="height:0.548em;min-width:1.6em;"><span class="brace-left" style="height:0.548em;"><svg width='400em' height='0.548em' viewBox='0 0 400000 548' preserveAspectRatio='xMinYMin slice'><path d='M0 6l6-6h17c12.688 0 19.313.3 20 1 4 4 7.313 8.3 10 13
 35.313 51.3 80.813 93.8 136.5 127.5 55.688 33.7 117.188 55.8 184.5 66.5.688
 0 2 .3 4 1 18.688 2.7 76 4.3 172 5h399450v120H429l-6-1c-124.688-8-235-61.7
-331-161C60.687 138.7 32.312 99.3 7 54L0 41V6z'/></svg></span><span class="brace-center" style="height:0.548em;"><svg width='400em' height='0.548em' viewBox='0 0 400000 548' preserveAspectRatio='xMidYMin slice'><path d='M199572 214
c100.7 8.3 195.3 44 280 108 55.3 42 101.7 93 139 153l9 14c2.7-4 5.7-8.7 9-14
 53.3-86.7 123.7-153 211-199 66.7-36 137.3-56.3 212-62h199568v120H200432c-178.3
 11.7-311.7 78.3-403 201-6 8-9.7 12-11 12-.7.7-6.7 1-18 1s-17.3-.3-18-1c-1.3 0
-5-4-11-12-44.7-59.3-101.3-106.3-170-141s-145.3-54.3-229-60H0V214z'/></svg></span><span class="brace-right" style="height:0.548em;"><svg width='400em' height='0.548em' viewBox='0 0 400000 548' preserveAspectRatio='xMaxYMin slice'><path d='M399994 0l6 6v35l-6 11c-56 104-135.3 181.3-238 232-57.3
 28.7-117 45-179 50H-300V214h399897c43.3-7 81-15 113-26 100.7-33 179.7-91 237
-174 2.7-5 6-9 10-13 .7-1 7.3-1 20-1h17z'/></svg></span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.5198em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3280857142857143em;"><span style="top:-2.357em;margin-left:-0.04398em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mrel mtight">∼</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3487714285714287em;margin-left:-0.03588em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">ϕ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.29011428571428566em;"><span></span></span></span></span></span></span><span class="minner mtight"><span class="mopen mtight delimcenter" style="top:0em;"><span class="mtight">(</span></span><span class="mord mathnormal mtight" style="margin-right:0.04398em;">z</span><span class="mrel mtight">∣</span><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3280857142857143em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mclose mtight delimcenter" style="top:0em;"><span class="mtight">)</span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.38327999999999984em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">[</span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">ψ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">)</span></span><span class="mclose delimcenter" style="top:0em;">]</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.0312799999999998em;"><span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.8534959999999996em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:2.4702159999999997em;vertical-align:-1.720216em;"></span><span class="mord munder"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.75em;"><span style="top:-1.415892em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">Stage 2: Masked Image Modeling </span></span></span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord munder"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.75em;"><span class="svg-align" style="top:-2.102em;"><span class="pstrut" style="height:3em;"></span><span class="stretchy" style="height:0.548em;min-width:1.6em;"><span class="brace-left" style="height:0.548em;"><svg width='400em' height='0.548em' viewBox='0 0 400000 548' preserveAspectRatio='xMinYMin slice'><path d='M0 6l6-6h17c12.688 0 19.313.3 20 1 4 4 7.313 8.3 10 13
 35.313 51.3 80.813 93.8 136.5 127.5 55.688 33.7 117.188 55.8 184.5 66.5.688
 0 2 .3 4 1 18.688 2.7 76 4.3 172 5h399450v120H429l-6-1c-124.688-8-235-61.7
-331-161C60.687 138.7 32.312 99.3 7 54L0 41V6z'/></svg></span><span class="brace-center" style="height:0.548em;"><svg width='400em' height='0.548em' viewBox='0 0 400000 548' preserveAspectRatio='xMidYMin slice'><path d='M199572 214
c100.7 8.3 195.3 44 280 108 55.3 42 101.7 93 139 153l9 14c2.7-4 5.7-8.7 9-14
 53.3-86.7 123.7-153 211-199 66.7-36 137.3-56.3 212-62h199568v120H200432c-178.3
 11.7-311.7 78.3-403 201-6 8-9.7 12-11 12-.7.7-6.7 1-18 1s-17.3-.3-18-1c-1.3 0
-5-4-11-12-44.7-59.3-101.3-106.3-170-141s-145.3-54.3-229-60H0V214z'/></svg></span><span class="brace-right" style="height:0.548em;"><svg width='400em' height='0.548em' viewBox='0 0 400000 548' preserveAspectRatio='xMaxYMin slice'><path d='M399994 0l6 6v35l-6 11c-56 104-135.3 181.3-238 232-57.3
 28.7-117 45-179 50H-300V214h399897c43.3-7 81-15 113-26 100.7-33 179.7-91 237
-174 2.7-5 6-9 10-13 .7-1 7.3-1 20-1h17z'/></svg></span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.69444em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.19444em;"><span class="mord">^</span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6678599999999999em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">x</span></span></span><span style="top:-3.35em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.22222em;"><span class="mord">~</span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.898em;"><span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.720216em;"><span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></p>
<p>其实，decoder 可以作为最后一层拼接到 bert 上，来还原原始的 patch ，但是作者这里没有使用，因为实验发现效果下降了 1.8% 。BEiT给出的猜想是，就像多层CNN一样，编码器最终得到的应该是一个更全局、高维的表示，而复现 patch 会让后几层太关注局部细节。</p>
<p>同时，个人觉得训练的 encoder 应该是这个模型的上限了吧，当然想学习的是关系，这一点倒是没什么问题。</p>
<br>
<p>微调：冻结 encoder</p>
<ol>
<li>分割任务</li>
<li>分类任务：没有使用 cls 直接做分类<br />
而是先将所有 token 做 linear map，然后 pooling，然后放入分类器分类</li>
</ol>
<h1 id="mae"><a class="markdownIt-Anchor" href="#mae"></a> MAE</h1>
<p>Blog：<br />
<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/448407149">CV预训练MAE（Masked AutoEncoder）</a><br />
<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/432950958">Self-Supervised Learning 超详细解读 (六)：MAE：通向 CV 大模型</a><br />
<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/529164676">一文看尽MAE最新进展！恺明的MAE已经提出大半年，目前发展如何？</a><br />
<a target="_blank" rel="noopener" href="https://www.zhihu.com/question/498364155/answer/2235134204">如何看待何恺明最新一作论文Masked Autoencoders? </a></p>
<p>Code：<br />
<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/483086713">MAE的理解和代码</a><br />
<a target="_blank" rel="noopener" href="https://github.com/FrancescoSaverioZuppichini/ViT">Implementing Vi(sual)T(transformer) in PyTorch</a><br />
<a target="_blank" rel="noopener" href="https://blog.csdn.net/zhe470719/article/details/124907059">【实验】vit代码</a></p>
<img src="/images/多模态/MAE.png" alt="981861843f708f9efb5f74829c336b3" style="zoom: 50%;" />
<p>动机：</p>
<ul>
<li>卷积是一个基于划窗的算法，它和其它嵌入（位置嵌入等）的融合比较困难。</li>
<li>信息密度不同：
<ul>
<li>文本数据比较密集，仅仅预测文本中的几个被掩码掉的单词就能很好的捕捉文本的语义特征。即 mask 率不高也能学习到整体的语言。</li>
<li>图像数据是一个信息密度非常小的矩阵，其中包含着大量的冗余信息，而且像素和它周围的像素仅仅在纹理上就有非常大的相似性，恢复被掩码的像素并不需要太多的语义信息。<br />
基于此，是需要将 mask ratio 调高到。</li>
</ul>
</li>
<li>解码器（ maps the latent representation back to the input）的作用不同（reconstruct text and images）：
<ul>
<li>文本数据的解码器需要了解文本的语义信息。预测一个 token 需要考虑全局的语义信息，输出语义级别很丰富（contain rich semantic information）。</li>
<li>在计算机视觉的掩码预测任务中，预测被掩码的像素（reconstructs pixels）往往对图像的语义信息依赖的并不严重，输出语义级别很低（of a lower semantic level）。</li>
<li>在 CV 领域，Decoder 的作用是重建 image pixels，所以 Decoder 的输出语义级别很低。在 NLP 领域，Decoder 的作用是重建 sentence words ，所以 Decoder 的输出语义级别很丰富。</li>
</ul>
</li>
</ul>
<p>火的一个原因：igpt 是生成模型，vit是判别模型，一半生成模型都比不上判别模型。但是 mae 其实算是生成模型，但是效果比判别模型要好很多。</p>
<p>核心：通过75%的高掩码率来对图像添加噪音，这样图像便很难通过周围的像素来对被掩码的像素进行重建，迫使编码器去学习图像中的语义信息。</p>
<p>模型：非对称的Encoder-Decoder架构的模型</p>
<ul>
<li>结构上：Encoder 参考 VIT，Decoder是一个轻量级的结构，它在深度和宽度上都比Encoder小很多。</li>
<li>输入上：Encoder仅将未被掩码的部分作为输入，而Decoder将整个图像的Patch（掩码标志和Encoder编码后的未被掩码patch的图像特征）作为输入。</li>
</ul>
<h2 id="模型"><a class="markdownIt-Anchor" href="#模型"></a> 模型</h2>
<p>an asymmetric encoder-decoder design -&gt; a large reduction in computation &amp; memory consumption<br />
Encoder 只输入 observed signal / unmasked patch ； Decoder 比较轻量（lightweight）</p>
<p><strong>Encoder : maps the observed signal to a latent representation</strong></p>
<p>这种做法可以大幅度降低原本图像的冗余度 largely eliminates redundancy ， creating a task that cannot be easily solved by extrapolation from visible neighboring patches。<br />
将输入减少了75%，因此训练速度也提高了75%。</p>
<p>模型部分就是 ViT ：</p>
<ul>
<li>输入不是整张图，而是只输入了未被掩码的部分 ; operates on a small subset (e.g., 25%) of the full set; Masked patches are removed</li>
<li>Encoder会为每一个未被掩码Patch计算一个特征向量，也要加 positional embedding 。<br />
encoder embeds patches by a linear projection with added positional embeddings</li>
<li>processes the resulting set via a series of Transformer blocks</li>
</ul>
<p><strong>Decoder : reconstructs the original signal from the latent representation</strong><br />
输入为 the full set of tokens ，包含两部分：</p>
<ol>
<li><strong>encoded visible patches：</strong> 一个是图像嵌入，它由 Encoder编码之后的特征</li>
<li><strong>mask tokens：</strong> Decoder的被掩码的标志是一个共享的且可以学习的嵌入 <code>[mask]</code> ，只是位置编码不一样。</li>
<li>都需要加上位置编码（ 整个图像的1-D位置编码 ）</li>
</ol>
<p>模型结果上，和 encoder 结构是相同的，不是自回归 token by token；参数是不同的。</p>
<p>MAE Decoder 仅用于预训练期间执行图像重建任务。做任务只用到了 Encoder 来得到 image representations 。<br />
自监督学习的特点就是只用最后预训练好的 Encoder 完成分类任务。</p>
<p>作者还对decoder 的参数量进行了对比，发现即使很小的参数量也和最后的模型表现差距不大。这表明了MAE的Encoder已经提取到了足够Decoder还原图像所需要的语义特征。</p>
<p><strong>Pre-train Loss</strong><br />
在 decoder 最后拼接一个 linear project，将输出的 patch 重构为 pixel values。所以 Decoder 的输出会进一步 reshape 成图像的形状 。<br />
损失函数就是 pixel-level MSE Loss，这里和 bert 一样，只去计算masked patches 上的 loss 。</p>
<p>作者还尝试了另外一种方案，计算 loss 前归一化一下：</p>
<ul>
<li>先计算出每个 patch 的像素值的 mean 和 deviation（the mean and standard deviation of all pixels in a patch），</li>
<li>使用它们去归一化这个 patch 的每个像素值。最后再使用归一化的像素值进行 MSE Loss 计算。发现这样做的效果比直接 MSE Loss 好 。</li>
</ul>
<p>微调：只使用 encoder 作为编码器，然后在后面添加对应的 decoder , 应该是添加随机初始化的 decoder。<br />
The MAE decoder is only used during pre-training to perform the image reconstruction task (only the encoder is used to produce image representations for recognition).</p>
<p>两种范式：</p>
<ol>
<li>full fine-tuning（更新所有模型参数）</li>
<li>linear probing （只更新最后一个linear layer参数）<br />
预训练模型的表征层的特征固定，参数固化后未发生改变，只通过监督数据去训练分类器（通常是Softmax分类器或者SVM分类器等等）。<br />
只训练这个线性层就是linear probe。这种方法可以用于更好地评估模型的表征学习能力强弱 。</li>
</ol>
<p><strong>Simple implementation</strong><br />
does not require any specialized sparse operations</p>
<ol>
<li>generate a token for every input patch (by linear projection with an added positional embedding)</li>
<li>randomly shuffle the list of tokens and remove the last portion of the list, based on the masking ratio -》 a small subset of tokens for the encoder</li>
<li>After encoding, we append a list of mask tokens to the list of encoded patches, and un-shuffle this full list</li>
<li>The decoder is applied to this full list (with positional embeddings added).</li>
</ol>
<h2 id="对比-vit"><a class="markdownIt-Anchor" href="#对比-vit"></a> 对比 vit</h2>
<p>原始 vit 论文中也尝试了 encoder 加入 mask，让模型尽心重构，而本文也对比了在 encoder 端加入了 mask，这样两者就是一个东西了，但是vit版本差很多 。<br />
为什么：<a target="_blank" rel="noopener" href="https://www.zhihu.com/question/498364155/answer/2239991489">如何看待何恺明最新一作论文Masked Autoencoders？</a></p>
<p>不过mae的下游任务好像是用encoder 进行的，而不是decoder的输出，所以能学到更深的语义。</p>
<h2 id="解释"><a class="markdownIt-Anchor" href="#解释"></a> 解释</h2>
<p>拼图重组任务巧妙学习了两个信息，一个是图片中部分物体之间的相邻关系（比如狗和地贴着）还有就是物体的位置（比如狗不在天上）拼图重组任务巧妙学习了两个信息，一个是图片中部分物体之间的相邻关系（比如狗和地贴着）还有就是物体的位置（比如狗不在天上）</p>
<h2 id="imagenet-experiments"><a class="markdownIt-Anchor" href="#imagenet-experiments"></a> ImageNet Experiments</h2>
<p>self-supervised pre-training on the ImageNet-1K (IN1K)</p>
<p>Baseline： ViT-Large (ViT-L/16)</p>
<p>增加 cls token在 encoder 端，作为图像整体表征，实验发现使用 avg pooling 效果也很好。</p>
<p>预训练之后，使用到两种微调方式：<br />
(i) end-to-end fine-tuning -&gt; 84.9<br />
(ii) linear probing，效果不如e2e fine-tune<br />
首先预训练阶段是像素级重构任务，而linear probing classifier执行的是分类任务，两者之间有一个明显的gap，这也就导致直接把用来完成像素级重构任务的latent representation拿过来用来分类，效果并不是特别好（65.5/70/71.9），那怎么样可以尽量提升效果呢？MAE decoder的深度非常重要，消融实验的结果告诉我们，需要找到一个合理的深度（8 blocks），此时latent representation的语义信息最抽象（more abstract level），更适合于分类任务，可以得到相对而言更好的分类结果（73.5）。</p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/446761025">https://zhuanlan.zhihu.com/p/446761025</a></p>
<h2 id="fine-tune"><a class="markdownIt-Anchor" href="#fine-tune"></a> Fine-tune</h2>
<p>object detection, instance segmentation, and semantic segmentation</p>

    </div>

    
    
    

      <footer class="post-footer">

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2022/03/03/NLP/%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/Multi-Head%20Selection/" rel="prev" title="Multi-Head Selection">
      <i class="fa fa-chevron-left"></i> Multi-Head Selection
    </a></div>
      <div class="post-nav-item">
    <a href="/2022/03/04/%E5%A4%9A%E6%A8%A1%E6%80%81/detection-Yolo/" rel="next" title="detection-Yolo">
      detection-Yolo <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#cnn-%E4%B8%AD%E7%9A%84-inductive-biases"><span class="nav-number">1.</span> <span class="nav-text"> CNN 中的 inductive biases</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#resnet"><span class="nav-number">2.</span> <span class="nav-text"> ResNet</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#resnext"><span class="nav-number">2.1.</span> <span class="nav-text"> ResNext</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#igpt"><span class="nav-number">3.</span> <span class="nav-text"> iGPT</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#ipt"><span class="nav-number">4.</span> <span class="nav-text"> IPT</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#vit"><span class="nav-number">5.</span> <span class="nav-text"> VIT</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%BD%92%E7%BA%B3%E5%81%8F%E6%89%A7%E5%88%86%E6%9E%90"><span class="nav-number">5.1.</span> <span class="nav-text"> 归纳偏执分析</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%B7%B7%E5%90%88%E7%BB%93%E6%9E%84"><span class="nav-number">5.2.</span> <span class="nav-text"> 混合结构</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#beit"><span class="nav-number">6.</span> <span class="nav-text"> BEiT</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#mae"><span class="nav-number">7.</span> <span class="nav-text"> MAE</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%A8%A1%E5%9E%8B"><span class="nav-number">7.1.</span> <span class="nav-text"> 模型</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%AF%B9%E6%AF%94-vit"><span class="nav-number">7.2.</span> <span class="nav-text"> 对比 vit</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%A7%A3%E9%87%8A"><span class="nav-number">7.3.</span> <span class="nav-text"> 解释</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#imagenet-experiments"><span class="nav-number">7.4.</span> <span class="nav-text"> ImageNet Experiments</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#fine-tune"><span class="nav-number">7.5.</span> <span class="nav-text"> Fine-tune</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name"></p>
  <div class="site-description" itemprop="description">A foolish, slow learner.</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives">
          <span class="site-state-item-count">361</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">40</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">2</span>
        <span class="site-state-item-name">tags</span>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/YiandLi" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;YiandLi" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://www.zhihu.com/people/yiliiiii" title="Zhihu → https:&#x2F;&#x2F;www.zhihu.com&#x2F;people&#x2F;yiliiiii" rel="noopener" target="_blank"><i class="fab fa-zhihu fa-fw"></i>Zhihu</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2024</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder"></span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
      <span class="post-meta-item-text">Symbols count total: </span>
    <span title="Symbols count total">620k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
      <span class="post-meta-item-text">Reading time total &asymp;</span>
    <span title="Reading time total">51:42</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>
